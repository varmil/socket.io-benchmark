# Simple socket.io benchmark.
(forked from https://github.com/michetti/socket.io-benchmark)

### There are two tests you can run:
* echo
	* each client sends a message to the server, which sends it back to the same client, which repeats the process forever.

* broadcast
	* each client sends a message to the server, which broadcasts it to all other clients. The server notify the client if the broadcast went ok, and then the client repeats the process forever.


### Installation:
1. clone this repository
1. on created dir, `npm i`
1. set ulimit `ulimit -u <desired ulimit>` `ulimit -n <desired ulimit>`

	* set ulimit to increase max number of opened sockets.


### Run:
1. Start server: `node app.js <port>`
	* transports is websocket
	* Port parameter is optional. If not specified, it will connect on port **3000**.
	* you can `DEBUG=* node app.js`
	* Log Option, see http://socket.io/docs/migrating-from-0-9/#log-differences

1. Start clients: `node benchmark.js <users> <rampup in seconds> <interval of emitting from client(ms)> <broadcast> <host> <port>`
	* Ex: `node benchmark.js 120 60` -> one new user every 0.5 seconds, until 120 users are connected.
	* Interval, broadcast, host and port parameters are optional. If not specified, then echo behaviour will be used, and it will connect to **localhost** on port **3000**.
	* Default interval is 100 ms. formula is `Math.round(Math.random() * interval * 0.1) + interval)`
	* Different Config Example: `node benchmark.js 120 60 1500 broadcast 192.168.1.50 4040`

### Advice:
* It is better to repeat step 2 multiple times than run it one time with a lot of users, since node is monothread.

### Run `node responsetime.js` :
* to see current response time. It will connect another user, that will send messages to the server, using the echo behaviour. The cicle time is logged in miliseconds.

### Output:
app.js will log the following line each second:

```
U: 100, MR/S: 2500, MS/S: 2500, MR/S/U: 25, MS/S/U: 25, CPU: 56, Mem: 1.8

U       -> Number of connected users
MR/S    -> Messages received per second
MS/S    -> Messages sended per second
MR/S/U  -> Messages received per second per user
MS/S/U  -> Messages sended per second per user
CPU     -> CPU usage percentage
Mem     -> Memory usage percentage
```

* To verify global resources utilization (by server and multiple clients processes), use `top`, `htop` (recomended) or something like it.


### Debug/Profilling:
Both app.js and benchmark.js have support for v8-profiler/node inspector.

To debug/profile app.js:

1. `node --debug app.js`
1. `node inspector &`
1. open the printed url (must be a webkit compatible browser, like chrome)


### TODO/Brainstorm:
* Make benchmark.js fork new processes to run clients, instead of running the script multiple times.
* Use redis store and create several server processes.
